import numpy as np
from numba import njit, prange, jit
import sys
import numba

sys.setrecursionlimit(40000)

import warnings

# turn off NumbaPendingDeprecationWarning
warnings.filterwarnings("ignore", category=numba.errors.NumbaPendingDeprecationWarning)


class CFG:
    def __init__(self, start, nonterminals, terminals, InferGeneralRuleOnly=True):
        self.start = start
        self.terminals = terminals
        self.nonterminals = nonterminals
        # This SCFG is sparse and not in chomsky normal form. THerefore the amount of rules is not fixed, but lesser
        # rules are of three types ( A-> BC, A-> a, A->B, A->aBc, where capital letters are nonterminals and small letters are terminals)
        # we will just call these type of rules as Transition, Emission, Replace, and ET (Emission and Transition)
        self.terminal_dict = {self.terminals[i]: i for i in range(len(self.terminals))}
        self.nonterminal_dict = {self.nonterminals[i]: i for i in range(len(self.nonterminals))}
        # for each non terminal, specify the type of rules it can have
        self.rule_present = np.zeros((len(self.nonterminals), 4))  # intially  no rules are applicable
        self.rules = self.init_rules()
        self.InferGeneralRuleOnly = InferGeneralRuleOnly
        self.rule_types = ["Transition", "Emission", "Replace", "Emmission-Transtion"]

    def init_rules(self):
        # create rules for each type
        Tr = np.zeros((len(self.nonterminals), len(self.nonterminals), len(self.nonterminals)))
        Er = np.zeros((len(self.nonterminals), len(self.terminals)))
        Rr = np.zeros((len(self.nonterminals), len(self.nonterminals)))
        ETr = np.zeros((len(self.nonterminals), len(self.terminals), len(self.nonterminals), len(self.terminals)))
        # set each element to -np.nan
        Tr.fill(np.nan)
        Er.fill(np.nan)
        Rr.fill(np.nan)
        ETr.fill(np.nan)

        return [Tr, Er, Rr, ETr]

    def activate_rules(self, rule):
        # here rule a is a tuple of (non terminal, ruletype, list of indices)
        nonterminal, ruletype, indices = rule
        nonterminal_ind = self.nonterminal_dict[nonterminal]
        self.rule_present[nonterminal_ind, ruletype] = 1
        if indices is None:
            # set all rules of this type to 0
            self.rules[ruletype][nonterminal_ind].fill(0)
        else:
            # fill only those indices, by forming a tuple of  (nonterminal, index1, index2, ...)
            indices = tuple([nonterminal_ind] + list(indices))
            self.rules[ruletype][indices] = 0

    def assign_random_probablities(self, single_freq=None, double_freq=None):
        counts = np.zeros((len(self.nonterminals), 4))
        for v in range(len(self.nonterminals)):
            # count the total number of non nan values
            for rule in range(4):
                if self.rule_present[v, rule] == 1:
                    counts[v, rule] = np.count_nonzero(~np.isnan(self.rules[rule][v]))
            # generate a probability distribution of length counts[v]
            dist = np.squeeze(np.random.dirichlet(np.ones(int(np.sum(counts[v]))), size=1))
            # fill the probabilities
            for rule in range(4):
                if self.rule_present[v, rule] == 1:
                    self.rules[rule][v][~np.isnan(self.rules[rule][v])] = dist[:int(counts[v, rule])]
                    dist = dist[int(counts[v, rule]):]
            if single_freq is None or double_freq is None:
                continue
            if self.rule_present[v, 1]:
                self.rules[1][v] = np.sum(self.rules[1][v]) * single_freq
            if self.rule_present[v, 3]:
                for w in range(len(self.nonterminals)):
                    if ~np.isnan(self.rules[3][v, 0, w, 0]):
                        self.rules[3][v, :, w, :] = np.sum(self.rules[3][v, :, w, :]) * double_freq
        return

    @staticmethod
    @jit(numba.f8[:, :, ::1](numba.i4[::1], numba.f8[:, :, ::1], numba.f8[:, ::1], numba.f8[:, ::1],
                             numba.f8[:, :, :, ::1], numba.f8[:, ::1], numba.i8, numba.f8[:, :, ::1]), nopython=True,
         cache=True)
    def inside_algorithm(string, tr_rule, e_rule, r_rule, et_rule, rule_present, n_non_terminals, alpha):
        # alpha is a 3d array of size ( len(string),len(string),n_non_terminals)
        # probability that a string starts at i, ends at j, and is generated by nonterminal k
        # L is a 3d array of size (n_non_terminals, n_non_terminals, len(string))
        # rules is a list of 4 3d arrays of size (n_non_terminals, n_non_terminals, n_non_terminals), (n_non_terminals, n_terminals), (n_non_terminals, n_non_terminals), (n_non_terminals, n_terminals, n_non_terminals, n_terminals)
        # initialize alpha to the emission rules
        L = len(string)
        for i in range(len(string)):
            for v in range(n_non_terminals):
                if rule_present[v, 1] == 1:
                    # print(rules[1][v, string[i]])
                    alpha[i, i, v] = e_rule[v, string[i]]
            for v in range(n_non_terminals):
                if rule_present[v, 2] == 1:
                    for x in range(n_non_terminals):
                        if np.isnan(r_rule[v, x]) or r_rule[v, x] == 0:
                            continue
                        alpha[i, i, v] += alpha[i, i, x] * r_rule[v, x]
        # fill the rest of the table
        for i in range(L - 1, -1, -1):
            for j in range(i + 1, L):
                for v in range(n_non_terminals - 1, -1, -1):
                    # lets go through all the rules that are present
                    if rule_present[v, 0] == 1:
                        # sum over all possible transitions
                        for x in range(n_non_terminals):
                            for y in range(n_non_terminals):
                                if np.isnan(tr_rule[v, x, y]) or tr_rule[v, x, y] == 0:
                                    continue
                                for k in range(i, j):
                                    alpha[i, j, v] += alpha[i, k, x] * alpha[k + 1, j, y] * tr_rule[v, x, y]
                    if rule_present[v, 2] == 1:
                        # sum over all possible replacements
                        for x in range(n_non_terminals):
                            if np.isnan(r_rule[v, x]):
                                continue
                            alpha[i, j, v] += alpha[i, j, x] * r_rule[v, x]
                    if rule_present[v, 3] == 1 and j - i > 1:
                        # sum over all possible  Transimission- emmission transitions
                        for x in range(n_non_terminals):
                            if np.isnan(et_rule[v, 0, x, 0]):
                                continue
                            alpha[i, j, v] += alpha[i + 1, j - 1, x] * et_rule[v, string[i], x, string[j]]
        return alpha

    @staticmethod
    @jit(numba.f8[:, :, ::1](numba.f8[:, :, ::1], numba.f8[:, ::1], numba.f8[:, :, :, ::1], numba.f8[:, ::1], numba.i8,
                             numba.f8[:, :, ::1], numba.f8[:, :, ::1], numba.i4[::1]), nopython=True, cache=True)
    def outside_algorithm(tr_rule, r_rule, et_rule, rule_present, n_non_terminals, beta, alpha, string):
        # probability that a string starts at i, ends at j, and is generated by nonterminal k
        # (i,j,v) probability that S(0,i), s(i+1,j) and non terminal v (between i and j) are generated by the grammar
        L = len(string)
        beta[0, L - 1, 0] = 1
        for i in range(1, n_non_terminals):
            beta[0, L - 1, i] = 0
        for i in range(0, L):
            for j in range(L - 1, i - 1, -1):
                for v in range(n_non_terminals):
                    # sum over all possible transitions
                    # there are 4 cases X->YV and X->VY, X->V and X->aVb
                    for x in range(n_non_terminals):
                        if rule_present[x, 0] == 1:
                            for y in range(n_non_terminals):
                                if tr_rule[x, y, v] == 0 or np.isnan(tr_rule[x, y, v]):
                                    continue
                                for k in range(0, i):
                                    beta[i, j, v] += tr_rule[x, y, v] * alpha[k, i - 1, y] * beta[k, j, x]

                                if tr_rule[x, v, y] == 0 or np.isnan(tr_rule[x, v, y]):
                                    continue
                                for k in range(j + 1, L):
                                    beta[i, j, v] += tr_rule[x, v, y] * alpha[j + 1, k, y] * beta[i, k, x]

                        if rule_present[x, 2] == 1:
                            if np.isnan(r_rule[x, v]):
                                continue
                            beta[i, j, v] += r_rule[x, v] * beta[i, j, x]

                        if rule_present[x, 3] == 1 and j - i > 1 and i > 0 and j < L - 1:
                            if np.isnan(et_rule[x, 0, v, 0]):
                                continue
                            beta[i, j, v] += et_rule[x, string[i], v, string[j]] * beta[i - 1, j + 1, x]
        return beta

    @staticmethod
    @jit((numba.i4[::1], numba.f8[:, :, ::1], numba.f8[:, ::1], numba.f8[:, ::1],
          numba.f8[:, :, :, ::1], numba.f8[:, ::1], numba.i8, numba.f8[:, :, ::1],
          numba.i4[:, :, :, ::1]), nopython=True, cache=True)
    def CYK_algorithm(string, tr_rule, e_rule, r_rule, et_rule, rule_present, n_non_terminals, gamma, tau):
        gamma.fill(-np.inf)
        tau.fill(-1)
        # (i,j,v) of \tau indicates the previous step that generated the maximum probability
        # each element is a 4 x1 vector [ rule,x,y,k] where rule is the rule that generated the maximum probability
        # if r==0 then  x,y,k where x,y are the non terminals , k is a splitting point
        # if r==1 then x is a terminal
        # if r==2 then x is the non-terminal
        # if r==3 then x is a non-terminal y,k are terminals
        log_tr = np.log(tr_rule)
        log_et = np.log(et_rule)
        log_r = np.log(r_rule)
        log_e = np.log(e_rule)
        L = len(string)
        prob = 0
        for i in range(L):
            for v in range(n_non_terminals):
                if rule_present[v, 1] == 1:
                    gamma[i, i, v] = log_e[v, string[i]]
                    tau[i, i, v] = [1, string[i], -1, -1]

            for v in range(n_non_terminals):
                if rule_present[v, 2] == 1:
                    for x in range(n_non_terminals):
                        prob = log_r[v, x] + gamma[i, i, x]
                        if np.isnan(r_rule[v, x]) or prob < gamma[i, i, v]:
                            continue
                        gamma[i, i, v] = prob
                        tau[i, i, v] = [2, x, -1, -1]

        for i in range(L - 1, -1, -1):
            for j in range(i + 1, L):
                for v in range(n_non_terminals - 1, -1, -1):
                    # Transition rules
                    if rule_present[v, 0] == 1:
                        for x in range(n_non_terminals):
                            for y in range(n_non_terminals):
                                if np.isnan(tr_rule[v, x, y]):
                                    continue
                                for k in range(i, j):
                                    prob = log_tr[v, x, y] + gamma[i, k, x] + gamma[k + 1, j, y]
                                    if prob < gamma[i, j, v]:
                                        continue
                                    gamma[i, j, v] = prob
                                    tau[i, j, v] = [0, x, y, k]
                    # R rules
                    if rule_present[v, 2] == 1:
                        for x in range(n_non_terminals):
                            if np.isnan(r_rule[v, x]):
                                continue
                            prob = log_r[v, x] + gamma[i, j, x]
                            if prob < gamma[i, j, v]:
                                continue
                            gamma[i, j, v] = prob
                            tau[i, j, v] = [2, x, -1, -1]
                    # ET rules
                    if rule_present[v, 3] == 1 and j - i > 1:
                        for x in range(n_non_terminals):
                            if np.isnan(et_rule[v, string[i], x, string[j]]):
                                continue
                            prob = log_et[v, string[i], x, string[j]] + gamma[i + 1, j - 1, x]
                            if prob < gamma[i, j, v]:
                                continue
                            gamma[i, j, v] = prob
                            tau[i, j, v] = [3, x, string[i], string[j]]
        return gamma, tau

    @staticmethod
    @njit(cache=True, parallel=True)
    def inside_outside_algorithm(strings, tr_rule, e_rule, r_rule, et_rule, rule_present, single_rules, double_rules,
                                 n_term, n_nonterm, inside_algorithm, outside_algorithm, *, n_iter=10, tol=1e-5):

        """
        :param strings: list of strings , each string is a numpy array of integers < n_term
        :param tr_rule:  transition rule, 3d array of size n_nonterm x n_nonterm x n_nonterm
        :param e_rule: emission rule, 3d array of size n_nonterm x n_term x n_nonterm
        :param r_rule: replacement rule, 2d array of size n_nonterm x n_nonterm
        :param et_rule: Emission-Transmission rule, 4d array of size n_nonterm x n_term x n_nonterm x n_term
        :param rule_present: 2d array of size n_nonterm x 4, 1 if the rule is present, 0 otherwise
        :param single_rules:  1d array indicating frequencies of differnet terminals of size n_term
        :param double_rules:  2d array indicating frequencies of base-pairs of size n_term x n_term
        :param n_term:  number of terminals
        :param n_nonterm:  number of non-terminals
        :param inside_algorithm:  function to calculate inside probabilities
        :param outside_algorithm:  function to calculate outside probabilities
        :param n_iter:  number of iterations
        :param tol:  tolerance
        :return:
        """
        # print(type(strings))
        LogLikelihood = np.zeros(n_iter + 1, dtype=float)
        EachLogLikelihood = np.zeros(len(strings), dtype=float)
        iteration = 0
        inners = [np.zeros((len(string), len(string), n_nonterm), dtype=float) for string in strings]
        outers = [np.zeros((len(string), len(string), n_nonterm), dtype=float) for string in strings]

        rules_denom = np.zeros(n_nonterm, dtype=float)
        rules_denom1 = np.zeros((len(strings), n_nonterm), dtype=float)

        tr_old, e_old, r_old, et_old = tr_rule.copy(), e_rule.copy(), r_rule.copy(), et_rule.copy()

        for s in range(len(strings)):
            inside_algorithm(strings[s], tr_rule, e_rule, r_rule, et_rule, rule_present, n_nonterm, inners[s])
            if inners[s][0, len(strings[s]) - 1, 0] == 0 or np.isnan(inners[s][0, len(strings[s]) - 1, 0]) or \
                    np.isinf(inners[s][0, len(strings[s]) - 1, 0]):
                print("string ", s, " is not accepted by the grammar")
            outside_algorithm(tr_rule, r_rule, et_rule, rule_present, n_nonterm, outers[s], inners[s], strings[s])
        print("First Expectation found")
        for s in prange(len(strings)):
            EachLogLikelihood[s] = -np.log(inners[s][0, len(strings[s]) - 1, 0]) / len(strings[s])
        LogLikelihood[iteration] = np.sum(EachLogLikelihood)
        print(iteration, round(LogLikelihood[iteration], 3))
        iteration += 1

        e_rule1 = np.zeros((len(strings), n_nonterm, n_term), dtype=float)
        tr_rule1 = np.zeros((len(strings), n_nonterm, n_nonterm, n_nonterm), dtype=float)
        r_rule1 = np.zeros((len(strings), n_nonterm, n_nonterm), dtype=float)
        et_rule1 = np.zeros((len(strings), n_nonterm, n_term, n_nonterm, n_term), dtype=float)

        while True:
            # set all non nan terms in rules to 0
            # NEED TO SET RULES TO ZERO
            # M step
            # update the transition and emission matrix
            rules_denom.fill(0)
            rules_denom1.fill(0)
            for v in prange(n_nonterm):
                # update the emission matrix
                if rule_present[v, 1] == 1:
                    e_rule[v, :] = 0
                    e_rule1[:, v, :] = 0
                    for s in range(len(strings)):
                        for i in range(len(strings[s])):
                            e_rule1[s, v, strings[s][i]] += outers[s][i, i, v] * e_old[v, strings[s][i]]
                        e_rule1[s, v, :] = np.sum(e_rule1[s, v, :]) * single_rules

                # update the transition matrix
                if rule_present[v, 0] == 1:
                    for y in range(n_nonterm):
                        for z in range(n_nonterm):
                            # check if the old transition probability is nan
                            if np.isnan(tr_rule[v, y, z]):
                                continue
                            tr_rule1[:, v, y, z] = 0
                            tr_rule[v, y, z] = 0
                            for s in range(len(strings)):
                                for i in range(len(strings[s])):
                                    for j in range(i + 1, len(strings[s])):
                                        for k in range(i, j):
                                            tr_rule1[s, v, y, z] += outers[s][i, j, v] * inners[s][i, k, y] * inners[s][
                                                k + 1, j, z] * tr_old[v, y, z]
                # update the replace rule
                if rule_present[v, 2] == 1:
                    for x in range(n_nonterm):
                        if np.isnan(r_rule[v, x]):
                            continue
                        r_rule1[:, v, x] = 0
                        r_rule[v, x] = 0
                        for s in range(len(strings)):
                            for i in range(len(strings[s])):
                                for j in range(i + 1, len(strings[s])):
                                    r_rule1[s, v, x] += outers[s][i, j, v] * inners[s][i, j, x] * r_old[v, x]
                # update the ET rule
                if rule_present[v, 3] == 1:
                    for x in range(n_nonterm):
                        if np.isnan(et_rule[v, 0, x, 0]):
                            continue
                        et_rule1[:, v, :, x, :] = 0
                        et_rule[v, :, x, :] = 0
                        for s in range(len(strings)):
                            for i in range(len(strings[s])):
                                for j in range(i + 2, len(strings[s])):
                                    et_rule1[s, v, strings[s][i], x, strings[s][j]] += outers[s][i, j, v] * inners[s][
                                        i + 1, j - 1, x] * et_old[v, strings[s][i], x, strings[s][j]]
                            et_rule1[s, v, :, x, :] = np.sum(et_rule1[s, v, :, x, :]) * double_rules

                for s in prange(len(strings)):
                    rules_denom1[s, v] = np.nansum(tr_rule1[s, v]) + np.nansum(e_rule1[s, v]) + np.nansum(
                        r_rule1[s, v]) + np.nansum(
                        et_rule1[s, v])
                    tr_rule1[s, v] /= rules_denom1[s, v]
                    e_rule1[s, v] /= rules_denom1[s, v]
                    r_rule1[s, v] /= rules_denom1[s, v]
                    et_rule1[s, v] /= rules_denom1[s, v]

                    tr_rule[v] += tr_rule1[s, v]
                    e_rule[v] += e_rule1[s, v]
                    r_rule[v] += r_rule1[s, v]
                    et_rule[v] += et_rule1[s, v]

                rules_denom[v] = np.nansum(tr_rule[v]) + np.nansum(e_rule[v]) + np.nansum(r_rule[v]) + np.nansum(
                    et_rule[v])
                tr_rule[v] /= rules_denom[v]
                e_rule[v] /= rules_denom[v]
                r_rule[v] /= rules_denom[v]
                et_rule[v] /= rules_denom[v]

            # E step
            # compute the inside and outside tables for each string
            for s in prange(len(strings)):
                inners[s].fill(0)
                outers[s].fill(0)
                inside_algorithm(strings[s], tr_rule, e_rule, r_rule, et_rule, rule_present, n_nonterm, inners[s])

                outside_algorithm(tr_rule, r_rule, et_rule, rule_present, n_nonterm, outers[s], inners[s],
                                  strings[s])

            # compute the log likelihood
            for s in prange(len(strings)):
                EachLogLikelihood[s] = -np.log(inners[s][0, len(strings[s]) - 1, 0]) // len(strings[s])
            LogLikelihood[iteration] = np.sum(EachLogLikelihood)
            print(iteration, round(LogLikelihood[iteration], 3))

            if iteration >= n_iter or np.abs(LogLikelihood[iteration] - LogLikelihood[iteration - 1]) < tol:
                break

            tr_old, tr_rule = tr_rule, tr_old
            e_old, e_rule = e_rule, e_old
            r_old, r_rule = r_rule, r_old
            et_old, et_rule = et_rule, et_old
            iteration += 1
        return tr_rule, e_rule, r_rule, et_rule, LogLikelihood, EachLogLikelihood

    def grammar_print_rules(self):
        n_nonterm = len(self.nonterminals)
        print("\nGrammar rules:")
        tr_rule, e_rule, r_rule, et_rule = self.rules[0], self.rules[1], self.rules[2], self.rules[3]
        for v in range(n_nonterm):
            if self.rule_present[v, 0] == 1:
                for y in range(n_nonterm):
                    for z in range(n_nonterm):
                        if not np.isnan(tr_rule[v, y, z]):
                            print(v, "->", y, z, ":", np.round(tr_rule[v, y, z], 3), end=';')

            if self.rule_present[v, 1] == 1:
                print(v, "-> s :", np.round(np.sum(e_rule[v]), 3), end=';')

            if self.rule_present[v, 2] == 1:
                for x in range(n_nonterm):
                    if not np.isnan(r_rule[v, x]):
                        print(v, "->", x, ":", np.round(r_rule[v, x], 3), end=';')

            if self.rule_present[v, 3] == 1:
                for x in range(n_nonterm):
                    if not np.isnan(et_rule[v, 0, x, 0]):
                        print(v, "->d", x, 'd :', np.round(np.sum(et_rule[v, :, x, :]), 3), end=';')
        print()

    def inside_out_driver(self, train_strings, val_strings, single_rules, double_rules, n_starts=10):
        train = self.convert_strings_to_int(train_strings, self.terminal_dict, "Train Data: ", ind=True)
        val = self.convert_strings_to_int(val_strings, self.terminal_dict, "Validation Data: ", ind=True)
        rule_start_list = []
        val_likelihood = np.zeros(n_starts, dtype=float)
        inner_vals = [np.zeros((len(s), len(s), len(self.nonterminal_dict)), dtype=float) for s in val]
        traceback_vals = [np.zeros((len(s), len(s), len(self.nonterminal_dict), 4), dtype=int) for s in val]
        n_nonterm = len(self.nonterminal_dict)
        for i in range(n_starts):
            print("\nIteration", end=' ')
            rule_start_list.append(
                [np.copy(self.rules[0]), np.copy(self.rules[1]), np.copy(self.rules[2]), np.copy(self.rules[3])])
            x = self.inside_outside_algorithm(train, self.rules[0], self.rules[1], self.rules[2], self.rules[3],
                                              self.rule_present, single_rules, double_rules, len(self.terminal_dict),
                                              len(self.nonterminal_dict), self.inside_algorithm, self.outside_algorithm,
                                              n_iter=20, tol=0.0001)
            tr_rule, e_rule, r_rule, et_rule, _, _ = x
            # use the CYK algorithm to compute the log likelihood of the validation set
            for s in range(len(val)):
                y, z = self.CYK_algorithm(val[s], tr_rule, e_rule, r_rule, et_rule, self.rule_present, n_nonterm,
                                          inner_vals[s], traceback_vals[s])
                val_likelihood[i] += y[0, len(val[s]) - 1, 0]
            print(f"Train Log-Likelihood: {np.round(x[4], 3)}, Val CYK logLikelihood {val_likelihood}")
            self.grammar_print_rules()
            self.assign_random_probablities(single_rules, double_rules)

        best_start = np.argmax(val_likelihood)

        tr_rule1, e_rule1, r_rule1, et_rule1 = rule_start_list[best_start]
        x = self.inside_outside_algorithm(train, tr_rule1, e_rule1, r_rule1, et_rule1,
                                          self.rule_present, single_rules, double_rules, len(self.terminal_dict),
                                          len(self.nonterminal_dict),
                                          self.inside_algorithm, self.outside_algorithm, n_iter=30, tol=0)
        tr_rule, e_rule, r_rule, et_rule, LogLikelihood, EachLogLikelihood = x
        self.rules = [tr_rule, e_rule, r_rule, et_rule]

        return LogLikelihood, EachLogLikelihood
        # return t

    @staticmethod
    def convert_strings_to_int(strings, terminal_dict, name=None, ind=False):
        intstrings = list()
        list_ind = list()
        wrong_bases = 0
        for s in range(len(strings)):
            intstrings.append(np.zeros_like(strings[s][0], dtype=int))
            strings[s][0] = np.char.upper(strings[s][0])
            for i in range(len(strings[s][0])):
                try:
                    intstrings[s][i] = terminal_dict[strings[s][0][i]]
                except KeyError:
                    intstrings[s][i] = np.random.randint(0, len(terminal_dict))
                    if ind:
                        list_ind.append(s)
                    wrong_bases += 1
        if name is not None:
            print(name, "wrong bases:", wrong_bases, end='\t')
            if ind:
                print("wrong bases in strings:", list_ind)
        return intstrings


# @njit((numba.i4[:, :, :, ::1], numba.i4[::1], numba.i4[::1]), cache=True)
def convert_CYK_parse_to_RNA(tau, pos, RNA_strand_pairings):
    # this store (index+1) of the base that is paired with the base at index, 0 if unpaired
    # this function is called recursively, the split happpening when there is a transition rule being appplied
    while True:
        rule, x, y, k = tau[pos[0], pos[1], pos[2]]
        if rule == 1:
            # emission rule (wil only occur at the end of the recursion)
            RNA_strand_pairings[pos[0]] = 0
            break
        elif rule == 2:
            # replacement rule (no useful information, just continue loop changin the position)
            pos[2] = x
        elif rule == 3:
            # T-E rule
            RNA_strand_pairings[pos[0]] = pos[1] + 1
            RNA_strand_pairings[pos[1]] = pos[0] + 1
            pos[2] = x
            pos[0] += 1
            pos[1] -= 1
        elif rule == 0:
            # transition rule (split the recursion)
            # split happens, such that we have to recurse for position string[pos[0],k,x] and string[k+1:pos[1],y]
            convert_CYK_parse_to_RNA(tau, [pos[0], k, x], RNA_strand_pairings)
            convert_CYK_parse_to_RNA(tau, [k + 1, pos[1], y], RNA_strand_pairings)
            break
    return


def get_pairings_from_parse_tree(traceback_vals, len_strings):
    # now we get the pairings from the parse tree
    pairings = [-np.ones(s, dtype=int) for s in len_strings]
    for i in range(len(len_strings)):
        convert_CYK_parse_to_RNA(traceback_vals[i], [0, len_strings[i] - 1, 0], pairings[i])

    return pairings
